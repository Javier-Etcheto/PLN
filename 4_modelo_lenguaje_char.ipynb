{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "7amy6uUaBLVD"
      },
      "outputs": [],
      "source": [
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# abro el archivo y me guardo todas las líneas\n",
        "with open('A_journey_to_the_Center_of_the_earth.txt', 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# busco dónde arranca y termina el texto útil\n",
        "start_idx = next(i for i, line in enumerate(lines) if '*** START OF' in line)\n",
        "#end_idx = next(i for i, line in enumerate(lines) if '*** END OF' in line)\n",
        "end_idx = next(i for i, line in enumerate(lines) if 'But I thought it best not to urge this argument' in line)\n",
        "\n",
        "# me quedo con las líneas del medio\n",
        "main_text_lines = lines[start_idx + 1:end_idx]\n",
        "\n",
        "# saco saltos de línea y uno todo en una sola string\n",
        "main_text = ' '.join(line.strip() for line in main_text_lines)\n",
        "\n",
        "# paso a minúsculas\n",
        "article_text = main_text.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "WBE0sSYuB-E6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"    produced by norm wolcott      a journey to the centre of the earth  by jules verne     [redactor's note: journey to the centre of the earth is number v002 in the taves and michaluk numbering of the works of jules verne. first published in england by griffith and farran, 1871, this edition is not a translation at all but a complete re-write of the novel, with portions added and omitted, and names changed. the most reprinted version, it is entered into project gutenberg for reference purposes only. a better translation is _a journey into the interior of the earth_ translated by rev. f. a. malleson, also available on project gutenberg.]     table of contents  chapter 1 my uncle makes a great discovery  chapter 2 the mysterious parchment  chapter 3 an astounding discovery  chapter 4 we start on the journey  chapter 5 first lessons in climbing  chapter 6 our voyage to iceland  chapter 7 conversation and discovery  chapter 8 the eider-down hunter--off at last  chapter 9 our start--we mee\""
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = sorted(set(article_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "VwTK6xgLJd8q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "PwGVSKOiJ5bj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 40,\n",
              " 42,\n",
              " 39,\n",
              " 28,\n",
              " 45,\n",
              " 27,\n",
              " 29,\n",
              " 28,\n",
              " 0,\n",
              " 26,\n",
              " 49,\n",
              " 0,\n",
              " 38,\n",
              " 39,\n",
              " 42,\n",
              " 37,\n",
              " 0,\n",
              " 47,\n",
              " 39,\n",
              " 36,\n",
              " 27,\n",
              " 39,\n",
              " 44,\n",
              " 44,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 25,\n",
              " 0,\n",
              " 34,\n",
              " 39,\n",
              " 45,\n",
              " 42,\n",
              " 38,\n",
              " 29,\n",
              " 49,\n",
              " 0,\n",
              " 44,\n",
              " 39,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 27,\n",
              " 29,\n",
              " 38,\n",
              " 44,\n",
              " 42,\n",
              " 29,\n",
              " 0,\n",
              " 39,\n",
              " 30,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 29,\n",
              " 25,\n",
              " 42,\n",
              " 44,\n",
              " 32,\n",
              " 0,\n",
              " 0,\n",
              " 26,\n",
              " 49,\n",
              " 0,\n",
              " 34,\n",
              " 45,\n",
              " 36,\n",
              " 29,\n",
              " 43,\n",
              " 0,\n",
              " 46,\n",
              " 29,\n",
              " 42,\n",
              " 38,\n",
              " 29,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 22,\n",
              " 42,\n",
              " 29,\n",
              " 28,\n",
              " 25,\n",
              " 27,\n",
              " 44,\n",
              " 39,\n",
              " 42,\n",
              " 3,\n",
              " 43,\n",
              " 0,\n",
              " 38,\n",
              " 39,\n",
              " 44,\n",
              " 29,\n",
              " 19,\n",
              " 0,\n",
              " 34,\n",
              " 39,\n",
              " 45,\n",
              " 42,\n",
              " 38,\n",
              " 29,\n",
              " 49,\n",
              " 0,\n",
              " 44,\n",
              " 39,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 27,\n",
              " 29,\n",
              " 38,\n",
              " 44,\n",
              " 42,\n",
              " 29,\n",
              " 0,\n",
              " 39,\n",
              " 30,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 29,\n",
              " 25,\n",
              " 42,\n",
              " 44,\n",
              " 32,\n",
              " 0,\n",
              " 33,\n",
              " 43,\n",
              " 0,\n",
              " 38,\n",
              " 45,\n",
              " 37,\n",
              " 26,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 46,\n",
              " 9,\n",
              " 9,\n",
              " 11,\n",
              " 0,\n",
              " 33,\n",
              " 38,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 44,\n",
              " 25,\n",
              " 46,\n",
              " 29,\n",
              " 43,\n",
              " 0,\n",
              " 25,\n",
              " 38,\n",
              " 28,\n",
              " 0,\n",
              " 37,\n",
              " 33,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 36,\n",
              " 45,\n",
              " 35,\n",
              " 0,\n",
              " 38,\n",
              " 45,\n",
              " 37,\n",
              " 26,\n",
              " 29,\n",
              " 42,\n",
              " 33,\n",
              " 38,\n",
              " 31,\n",
              " 0,\n",
              " 39,\n",
              " 30,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 47,\n",
              " 39,\n",
              " 42,\n",
              " 35,\n",
              " 43,\n",
              " 0,\n",
              " 39,\n",
              " 30,\n",
              " 0,\n",
              " 34,\n",
              " 45,\n",
              " 36,\n",
              " 29,\n",
              " 43,\n",
              " 0,\n",
              " 46,\n",
              " 29,\n",
              " 42,\n",
              " 38,\n",
              " 29,\n",
              " 8,\n",
              " 0,\n",
              " 30,\n",
              " 33,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 0,\n",
              " 40,\n",
              " 45,\n",
              " 26,\n",
              " 36,\n",
              " 33,\n",
              " 43,\n",
              " 32,\n",
              " 29,\n",
              " 28,\n",
              " 0,\n",
              " 33,\n",
              " 38,\n",
              " 0,\n",
              " 29,\n",
              " 38,\n",
              " 31,\n",
              " 36,\n",
              " 25,\n",
              " 38,\n",
              " 28,\n",
              " 0,\n",
              " 26,\n",
              " 49,\n",
              " 0,\n",
              " 31,\n",
              " 42,\n",
              " 33,\n",
              " 30,\n",
              " 30,\n",
              " 33,\n",
              " 44,\n",
              " 32,\n",
              " 0,\n",
              " 25,\n",
              " 38,\n",
              " 28,\n",
              " 0,\n",
              " 30,\n",
              " 25,\n",
              " 42,\n",
              " 42,\n",
              " 25,\n",
              " 38,\n",
              " 6,\n",
              " 0,\n",
              " 10,\n",
              " 17,\n",
              " 16,\n",
              " 10,\n",
              " 6,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 33,\n",
              " 43,\n",
              " 0,\n",
              " 29,\n",
              " 28,\n",
              " 33,\n",
              " 44,\n",
              " 33,\n",
              " 39,\n",
              " 38,\n",
              " 0,\n",
              " 33,\n",
              " 43,\n",
              " 0,\n",
              " 38,\n",
              " 39,\n",
              " 44,\n",
              " 0,\n",
              " 25,\n",
              " 0,\n",
              " 44,\n",
              " 42,\n",
              " 25,\n",
              " 38,\n",
              " 43,\n",
              " 36,\n",
              " 25,\n",
              " 44,\n",
              " 33,\n",
              " 39,\n",
              " 38,\n",
              " 0,\n",
              " 25,\n",
              " 44,\n",
              " 0,\n",
              " 25,\n",
              " 36,\n",
              " 36,\n",
              " 0,\n",
              " 26,\n",
              " 45,\n",
              " 44,\n",
              " 0,\n",
              " 25,\n",
              " 0,\n",
              " 27,\n",
              " 39,\n",
              " 37,\n",
              " 40,\n",
              " 36,\n",
              " 29,\n",
              " 44,\n",
              " 29,\n",
              " 0,\n",
              " 42,\n",
              " 29,\n",
              " 7,\n",
              " 47,\n",
              " 42,\n",
              " 33,\n",
              " 44,\n",
              " 29,\n",
              " 0,\n",
              " 39,\n",
              " 30,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 38,\n",
              " 39,\n",
              " 46,\n",
              " 29,\n",
              " 36,\n",
              " 6,\n",
              " 0,\n",
              " 47,\n",
              " 33,\n",
              " 44,\n",
              " 32,\n",
              " 0,\n",
              " 40,\n",
              " 39,\n",
              " 42,\n",
              " 44,\n",
              " 33,\n",
              " 39,\n",
              " 38,\n",
              " 43,\n",
              " 0,\n",
              " 25,\n",
              " 28,\n",
              " 28,\n",
              " 29,\n",
              " 28,\n",
              " 0,\n",
              " 25,\n",
              " 38,\n",
              " 28,\n",
              " 0,\n",
              " 39,\n",
              " 37,\n",
              " 33,\n",
              " 44,\n",
              " 44,\n",
              " 29,\n",
              " 28,\n",
              " 6,\n",
              " 0,\n",
              " 25,\n",
              " 38,\n",
              " 28,\n",
              " 0,\n",
              " 38,\n",
              " 25,\n",
              " 37,\n",
              " 29,\n",
              " 43,\n",
              " 0,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 38,\n",
              " 31,\n",
              " 29,\n",
              " 28,\n",
              " 8,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 37,\n",
              " 39,\n",
              " 43,\n",
              " 44,\n",
              " 0,\n",
              " 42,\n",
              " 29,\n",
              " 40,\n",
              " 42,\n",
              " 33,\n",
              " 38,\n",
              " 44,\n",
              " 29,\n",
              " 28,\n",
              " 0,\n",
              " 46,\n",
              " 29,\n",
              " 42,\n",
              " 43,\n",
              " 33,\n",
              " 39,\n",
              " 38,\n",
              " 6,\n",
              " 0,\n",
              " 33,\n",
              " 44,\n",
              " 0,\n",
              " 33,\n",
              " 43,\n",
              " 0,\n",
              " 29,\n",
              " 38,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 29,\n",
              " 28,\n",
              " 0,\n",
              " 33,\n",
              " 38,\n",
              " 44,\n",
              " 39,\n",
              " 0,\n",
              " 40,\n",
              " 42,\n",
              " 39,\n",
              " 34,\n",
              " 29,\n",
              " 27,\n",
              " 44,\n",
              " 0,\n",
              " 31,\n",
              " 45,\n",
              " 44,\n",
              " 29,\n",
              " 38,\n",
              " 26,\n",
              " 29,\n",
              " 42,\n",
              " 31,\n",
              " 0,\n",
              " 30,\n",
              " 39,\n",
              " 42,\n",
              " 0,\n",
              " 42,\n",
              " 29,\n",
              " 30,\n",
              " 29,\n",
              " 42,\n",
              " 29,\n",
              " 38,\n",
              " 27,\n",
              " 29,\n",
              " 0,\n",
              " 40,\n",
              " 45,\n",
              " 42,\n",
              " 40,\n",
              " 39,\n",
              " 43,\n",
              " 29,\n",
              " 43,\n",
              " 0,\n",
              " 39,\n",
              " 38,\n",
              " 36,\n",
              " 49,\n",
              " 8,\n",
              " 0,\n",
              " 25,\n",
              " 0,\n",
              " 26,\n",
              " 29,\n",
              " 44,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 44,\n",
              " 42,\n",
              " 25,\n",
              " 38,\n",
              " 43,\n",
              " 36,\n",
              " 25,\n",
              " 44,\n",
              " 33,\n",
              " 39,\n",
              " 38,\n",
              " 0,\n",
              " 33,\n",
              " 43,\n",
              " 0,\n",
              " 24,\n",
              " 25,\n",
              " 0,\n",
              " 34,\n",
              " 39,\n",
              " 45,\n",
              " 42,\n",
              " 38,\n",
              " 29,\n",
              " 49,\n",
              " 0,\n",
              " 33,\n",
              " 38,\n",
              " 44,\n",
              " 39,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 33,\n",
              " 38,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 33,\n",
              " 39,\n",
              " 42,\n",
              " 0,\n",
              " 39,\n",
              " 30,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 29,\n",
              " 25,\n",
              " 42,\n",
              " 44,\n",
              " 32,\n",
              " 24,\n",
              " 0,\n",
              " 44,\n",
              " 42,\n",
              " 25,\n",
              " 38,\n",
              " 43,\n",
              " 36,\n",
              " 25,\n",
              " 44,\n",
              " 29,\n",
              " 28,\n",
              " 0,\n",
              " 26,\n",
              " 49,\n",
              " 0,\n",
              " 42,\n",
              " 29,\n",
              " 46,\n",
              " 8,\n",
              " 0,\n",
              " 30,\n",
              " 8,\n",
              " 0,\n",
              " 25,\n",
              " 8,\n",
              " 0,\n",
              " 37,\n",
              " 25,\n",
              " 36,\n",
              " 36,\n",
              " 29,\n",
              " 43,\n",
              " 39,\n",
              " 38,\n",
              " 6,\n",
              " 0,\n",
              " 25,\n",
              " 36,\n",
              " 43,\n",
              " 39,\n",
              " 0,\n",
              " 25,\n",
              " 46,\n",
              " 25,\n",
              " 33,\n",
              " 36,\n",
              " 25,\n",
              " 26,\n",
              " 36,\n",
              " 29,\n",
              " 0,\n",
              " 39,\n",
              " 38,\n",
              " 0,\n",
              " 40,\n",
              " 42,\n",
              " 39,\n",
              " 34,\n",
              " 29,\n",
              " 27,\n",
              " 44,\n",
              " 0,\n",
              " 31,\n",
              " 45,\n",
              " 44,\n",
              " 29,\n",
              " 38,\n",
              " 26,\n",
              " 29,\n",
              " 42,\n",
              " 31,\n",
              " 8,\n",
              " 23,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 44,\n",
              " 25,\n",
              " 26,\n",
              " 36,\n",
              " 29,\n",
              " 0,\n",
              " 39,\n",
              " 30,\n",
              " 0,\n",
              " 27,\n",
              " 39,\n",
              " 38,\n",
              " 44,\n",
              " 29,\n",
              " 38,\n",
              " 44,\n",
              " 43,\n",
              " 0,\n",
              " 0,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 40,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 10,\n",
              " 0,\n",
              " 37,\n",
              " 49,\n",
              " 0,\n",
              " 45,\n",
              " 38,\n",
              " 27,\n",
              " 36,\n",
              " 29,\n",
              " 0,\n",
              " 37,\n",
              " 25,\n",
              " 35,\n",
              " 29,\n",
              " 43,\n",
              " 0,\n",
              " 25,\n",
              " 0,\n",
              " 31,\n",
              " 42,\n",
              " 29,\n",
              " 25,\n",
              " 44,\n",
              " 0,\n",
              " 28,\n",
              " 33,\n",
              " 43,\n",
              " 27,\n",
              " 39,\n",
              " 46,\n",
              " 29,\n",
              " 42,\n",
              " 49,\n",
              " 0,\n",
              " 0,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 40,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 11,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 37,\n",
              " 49,\n",
              " 43,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 33,\n",
              " 39,\n",
              " 45,\n",
              " 43,\n",
              " 0,\n",
              " 40,\n",
              " 25,\n",
              " 42,\n",
              " 27,\n",
              " 32,\n",
              " 37,\n",
              " 29,\n",
              " 38,\n",
              " 44,\n",
              " 0,\n",
              " 0,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 40,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 12,\n",
              " 0,\n",
              " 25,\n",
              " 38,\n",
              " 0,\n",
              " 25,\n",
              " 43,\n",
              " 44,\n",
              " 39,\n",
              " 45,\n",
              " 38,\n",
              " 28,\n",
              " 33,\n",
              " 38,\n",
              " 31,\n",
              " 0,\n",
              " 28,\n",
              " 33,\n",
              " 43,\n",
              " 27,\n",
              " 39,\n",
              " 46,\n",
              " 29,\n",
              " 42,\n",
              " 49,\n",
              " 0,\n",
              " 0,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 40,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 13,\n",
              " 0,\n",
              " 47,\n",
              " 29,\n",
              " 0,\n",
              " 43,\n",
              " 44,\n",
              " 25,\n",
              " 42,\n",
              " 44,\n",
              " 0,\n",
              " 39,\n",
              " 38,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 34,\n",
              " 39,\n",
              " 45,\n",
              " 42,\n",
              " 38,\n",
              " 29,\n",
              " 49,\n",
              " 0,\n",
              " 0,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 40,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 14,\n",
              " 0,\n",
              " 30,\n",
              " 33,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 0,\n",
              " 36,\n",
              " 29,\n",
              " 43,\n",
              " 43,\n",
              " 39,\n",
              " 38,\n",
              " 43,\n",
              " 0,\n",
              " 33,\n",
              " 38,\n",
              " 0,\n",
              " 27,\n",
              " 36,\n",
              " 33,\n",
              " 37,\n",
              " 26,\n",
              " 33,\n",
              " 38,\n",
              " 31,\n",
              " 0,\n",
              " 0,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 40,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 15,\n",
              " 0,\n",
              " 39,\n",
              " 45,\n",
              " 42,\n",
              " 0,\n",
              " 46,\n",
              " 39,\n",
              " 49,\n",
              " 25,\n",
              " 31,\n",
              " 29,\n",
              " 0,\n",
              " 44,\n",
              " 39,\n",
              " 0,\n",
              " 33,\n",
              " 27,\n",
              " 29,\n",
              " 36,\n",
              " 25,\n",
              " 38,\n",
              " 28,\n",
              " 0,\n",
              " 0,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 40,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 16,\n",
              " 0,\n",
              " 27,\n",
              " 39,\n",
              " 38,\n",
              " 46,\n",
              " 29,\n",
              " 42,\n",
              " 43,\n",
              " 25,\n",
              " 44,\n",
              " 33,\n",
              " 39,\n",
              " 38,\n",
              " 0,\n",
              " 25,\n",
              " 38,\n",
              " 28,\n",
              " 0,\n",
              " 28,\n",
              " 33,\n",
              " 43,\n",
              " 27,\n",
              " 39,\n",
              " 46,\n",
              " 29,\n",
              " 42,\n",
              " 49,\n",
              " 0,\n",
              " 0,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 40,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 17,\n",
              " 0,\n",
              " 44,\n",
              " 32,\n",
              " 29,\n",
              " 0,\n",
              " 29,\n",
              " 33,\n",
              " 28,\n",
              " 29,\n",
              " 42,\n",
              " 7,\n",
              " 28,\n",
              " 39,\n",
              " 47,\n",
              " 38,\n",
              " 0,\n",
              " 32,\n",
              " 45,\n",
              " 38,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 7,\n",
              " 7,\n",
              " 39,\n",
              " 30,\n",
              " 30,\n",
              " 0,\n",
              " 25,\n",
              " 44,\n",
              " 0,\n",
              " 36,\n",
              " 25,\n",
              " 43,\n",
              " 44,\n",
              " 0,\n",
              " 0,\n",
              " 27,\n",
              " 32,\n",
              " 25,\n",
              " 40,\n",
              " 44,\n",
              " 29,\n",
              " 42,\n",
              " 0,\n",
              " 18,\n",
              " 0,\n",
              " 39,\n",
              " 45,\n",
              " 42,\n",
              " 0,\n",
              " 43,\n",
              " 44,\n",
              " 25,\n",
              " 42,\n",
              " 44,\n",
              " 7,\n",
              " 7,\n",
              " 47,\n",
              " 29,\n",
              " 0,\n",
              " 37,\n",
              " 29,\n",
              " 29]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "#X = np.array(tokenized_sentences_train[:-1])\n",
        "#y = np.array(tokenized_sentences_train[1:])\n",
        "X = np.array([seq[:-1] for seq in tokenized_sentences_train])\n",
        "y = np.array([seq[1:] for seq in tokenized_sentences_train])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "KFAyA4zCWE-5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(206268, 99)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "qcKRl70HFTzG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0, 40, 42, 39, 28, 45, 27])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "TVpLCKSZFXZO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  0,  0, 40, 42, 39, 28, 45, 27, 29])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, LSTM, GRU, Dense\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgz7VKwTUbj6"
      },
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_rnn = Sequential()\n",
        "model_rnn.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=None))  \n",
        "model_rnn.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "model_rnn.add(Dense(vocab_size, activation='softmax'))\n",
        "model_rnn.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=None))  \n",
        "model_lstm.add(LSTM(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "model_lstm.add(Dense(vocab_size, activation='softmax'))\n",
        "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gru = Sequential()\n",
        "model_gru.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=None)) \n",
        "model_gru.add(GRU(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "model_gru.add(Dense(vocab_size, activation='softmax'))\n",
        "model_gru.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl, model_name, patience=3):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "      \n",
        "      self.model_name = model_name\n",
        "      self.history_ppl = history_ppl\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        self.history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(self.model_name)\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQq1PHDkxDvN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.2767\n",
            " mean perplexity: 5.743627518683552 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 148ms/step - loss: 2.2763\n",
            "Epoch 2/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.6557\n",
            " mean perplexity: 5.194293021200264 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 144ms/step - loss: 1.6557\n",
            "Epoch 3/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.5526\n",
            " mean perplexity: 5.005106679658587 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 148ms/step - loss: 1.5526\n",
            "Epoch 4/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.5105\n",
            " mean perplexity: 4.902304569759687 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 141ms/step - loss: 1.5104\n",
            "Epoch 5/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 1.4871\n",
            " mean perplexity: 4.8613935188890345 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 88ms/step - loss: 1.4871\n",
            "Epoch 6/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 1.4716\n",
            " mean perplexity: 4.85081186077756 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 85ms/step - loss: 1.4716\n",
            "Epoch 7/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 1.4609\n",
            " mean perplexity: 4.818059612739635 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 85ms/step - loss: 1.4609\n",
            "Epoch 8/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.4518\n",
            " mean perplexity: 4.766003559137505 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 95ms/step - loss: 1.4518\n",
            "Epoch 9/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.4458\n",
            " mean perplexity: 4.770584487322935 \n",
            "\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 101ms/step - loss: 1.4458\n",
            "Epoch 10/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.4411\n",
            " mean perplexity: 4.767005285161892 \n",
            "\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 101ms/step - loss: 1.4411\n",
            "Epoch 11/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 1.4358\n",
            " mean perplexity: 4.703453289205553 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 99ms/step - loss: 1.4358\n",
            "Epoch 12/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.4313\n",
            " mean perplexity: 4.723587328859889 \n",
            "\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 101ms/step - loss: 1.4313\n",
            "Epoch 13/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.4285\n",
            " mean perplexity: 4.738800200333204 \n",
            "\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 100ms/step - loss: 1.4285\n",
            "Epoch 14/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 1.4251\n",
            " mean perplexity: 4.718194614886766 \n",
            "\n",
            "Stopping training...\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 101ms/step - loss: 1.4251\n",
            "Epoch 1/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - loss: 2.5701\n",
            " mean perplexity: 7.558493016318709 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 368ms/step - loss: 2.5697\n",
            "Epoch 2/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - loss: 1.9076\n",
            " mean perplexity: 6.3170224975746265 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 385ms/step - loss: 1.9075\n",
            "Epoch 3/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - loss: 1.7386\n",
            " mean perplexity: 5.840975280427456 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 381ms/step - loss: 1.7386\n",
            "Epoch 4/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - loss: 1.6405\n",
            " mean perplexity: 5.619658195796229 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 352ms/step - loss: 1.6405\n",
            "Epoch 5/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - loss: 1.5762\n",
            " mean perplexity: 5.41746478568137 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 350ms/step - loss: 1.5762\n",
            "Epoch 6/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 1.5261\n",
            " mean perplexity: 5.332555473454947 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 371ms/step - loss: 1.5261\n",
            "Epoch 7/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 1.4888\n",
            " mean perplexity: 5.245335701924943 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 370ms/step - loss: 1.4888\n",
            "Epoch 8/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - loss: 1.4583\n",
            " mean perplexity: 5.20952645547821 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 365ms/step - loss: 1.4583\n",
            "Epoch 9/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - loss: 1.4347\n",
            " mean perplexity: 5.177695169075529 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 365ms/step - loss: 1.4347\n",
            "Epoch 10/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 1.4147\n",
            " mean perplexity: 5.057332918753164 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 363ms/step - loss: 1.4147\n",
            "Epoch 11/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - loss: 1.3972\n",
            " mean perplexity: 5.044286036639717 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 363ms/step - loss: 1.3972\n",
            "Epoch 12/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - loss: 1.3826\n",
            " mean perplexity: 4.938878531297138 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 366ms/step - loss: 1.3826\n",
            "Epoch 13/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 1.3697\n",
            " mean perplexity: 4.918608449072136 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 363ms/step - loss: 1.3697\n",
            "Epoch 14/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - loss: 1.3585\n",
            " mean perplexity: 4.882337727970688 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 368ms/step - loss: 1.3585\n",
            "Epoch 15/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - loss: 1.3466\n",
            " mean perplexity: 4.868402952273805 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 364ms/step - loss: 1.3466\n",
            "Epoch 16/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 1.3367\n",
            " mean perplexity: 4.8283293752681775 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 363ms/step - loss: 1.3367\n",
            "Epoch 17/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - loss: 1.3255\n",
            " mean perplexity: 4.845786080463973 \n",
            "\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 366ms/step - loss: 1.3255\n",
            "Epoch 18/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - loss: 1.3164\n",
            " mean perplexity: 4.826600228377699 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 369ms/step - loss: 1.3164\n",
            "Epoch 19/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - loss: 1.3065\n",
            " mean perplexity: 4.800254844314591 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 369ms/step - loss: 1.3065\n",
            "Epoch 20/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 1.2959\n",
            " mean perplexity: 4.8529144188198 \n",
            "\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 370ms/step - loss: 1.2959\n",
            "Epoch 1/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 2.3873\n",
            " mean perplexity: 5.783477485271217 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 300ms/step - loss: 2.3869\n",
            "Epoch 2/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 1.6140\n",
            " mean perplexity: 5.013672579574277 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 255ms/step - loss: 1.6140\n",
            "Epoch 3/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 1.4406\n",
            " mean perplexity: 4.845082191228468 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 263ms/step - loss: 1.4406\n",
            "Epoch 4/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 1.3652\n",
            " mean perplexity: 4.737787176458144 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 262ms/step - loss: 1.3651\n",
            "Epoch 5/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 1.3223\n",
            " mean perplexity: 4.706009002505028 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 265ms/step - loss: 1.3223\n",
            "Epoch 6/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 1.2944\n",
            " mean perplexity: 4.73902721940434 \n",
            "\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 262ms/step - loss: 1.2944\n",
            "Epoch 7/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 1.2742\n",
            " mean perplexity: 4.7017749416295365 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 264ms/step - loss: 1.2742\n",
            "Epoch 8/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 1.2596\n",
            " mean perplexity: 4.713490951594159 \n",
            "\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 275ms/step - loss: 1.2596\n",
            "Epoch 9/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 1.2472\n",
            " mean perplexity: 4.681417771405006 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 266ms/step - loss: 1.2472\n",
            "Epoch 10/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 1.2368\n",
            " mean perplexity: 4.74597431115504 \n",
            "\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 268ms/step - loss: 1.2368\n",
            "Epoch 11/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 1.2290\n",
            " mean perplexity: 4.751670696033542 \n",
            "\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 271ms/step - loss: 1.2290\n",
            "Epoch 12/20\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 1.2218\n",
            " mean perplexity: 4.792226547236228 \n",
            "\n",
            "Stopping training...\n",
            "\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 267ms/step - loss: 1.2218\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "#history_ppl_rnn = []\n",
        "#hist_rnn = model_rnn.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl_rnn,model_name=\"model_rnn.keras\")], batch_size=256)\n",
        "\n",
        "#history_ppl_lstm = []\n",
        "#hist_lstm = model_lstm.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl_lstm,model_name=\"model_lstm.keras\")], batch_size=256)\n",
        "\n",
        "#history_ppl_gru = []\n",
        "#hist_gru = model_gru.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl_gru,model_name=\"model_gru.keras\")], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#np.save(\"history_ppl_rnn.npy\", np.array(history_ppl_rnn))\n",
        "#np.save(\"history_ppl_lstm.npy\", np.array(history_ppl_lstm))\n",
        "#np.save(\"history_ppl_gru.npy\", np.array(history_ppl_gru))\n",
        "\n",
        "# Para cargar los historiales de perplejidad\n",
        "history_ppl_rnn = np.load(\"history_ppl_rnn.npy\").tolist()\n",
        "history_ppl_lstm = np.load(\"history_ppl_lstm.npy\").tolist()\n",
        "history_ppl_gru = np.load(\"history_ppl_gru.npy\").tolist()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "K30JHB3Dv-mx"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.DataFrame([\n",
        "    {\"epoch\": i, \"perplexity\": val, \"model\": m}\n",
        "    for m, history in zip([\"RNN\",\"LSTM\",\"GRU\"], [history_ppl_rnn, history_ppl_lstm, history_ppl_gru])\n",
        "    for i, val in enumerate(history, 1)\n",
        "])\n",
        "\n",
        "sns.lineplot(data=df, x=\"epoch\", y=\"perplexity\", hue=\"model\")\n",
        "plt.title(\"Perplexity vs Epoch\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Todos los modelos reducen la perplejidad durante el entrenamiento y se detienen automáticamente por paciencia cuando no hay mejora.\n",
        "\n",
        "El RNN logra una perplejidad estable alrededor de 4.6 desde la época 5.\n",
        "\n",
        "El LSTM inicia con valores más altos pero mejora consistentemente hasta cerca de 4.6-4.7, deteniéndose tras tres épocas sin mejora (probé con más epocas de patience pero no mejora).\n",
        "\n",
        "El GRU baja rápido y alcanza ~4.8 en la época 5, aunque luego presenta mayor variabilidad.\n",
        "\n",
        "En general, RNN y LSTM muestran mayor estabilidad hacia el final, mientras que GRU tiene mejor desempeño inicial pero fluctuaciones posteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity for RNN:\n",
            "  Epoch 1: 5.7436\n",
            "  Epoch 2: 5.1943\n",
            "  Epoch 3: 5.0051\n",
            "  Epoch 4: 4.9023\n",
            "  Epoch 5: 4.8614\n",
            "  Epoch 6: 4.8508\n",
            "  Epoch 7: 4.8181\n",
            "  Epoch 8: 4.7660\n",
            "  Epoch 9: 4.7706\n",
            "  Epoch 10: 4.7670\n",
            "  Epoch 11: 4.7035\n",
            "  Epoch 12: 4.7236\n",
            "  Epoch 13: 4.7388\n",
            "  Epoch 14: 4.7182\n",
            "\n",
            "Perplexity for LSTM:\n",
            "  Epoch 1: 7.5585\n",
            "  Epoch 2: 6.3170\n",
            "  Epoch 3: 5.8410\n",
            "  Epoch 4: 5.6197\n",
            "  Epoch 5: 5.4175\n",
            "  Epoch 6: 5.3326\n",
            "  Epoch 7: 5.2453\n",
            "  Epoch 8: 5.2095\n",
            "  Epoch 9: 5.1777\n",
            "  Epoch 10: 5.0573\n",
            "  Epoch 11: 5.0443\n",
            "  Epoch 12: 4.9389\n",
            "  Epoch 13: 4.9186\n",
            "  Epoch 14: 4.8823\n",
            "  Epoch 15: 4.8684\n",
            "  Epoch 16: 4.8283\n",
            "  Epoch 17: 4.8458\n",
            "  Epoch 18: 4.8266\n",
            "  Epoch 19: 4.8003\n",
            "  Epoch 20: 4.8529\n",
            "\n",
            "Perplexity for GRU:\n",
            "  Epoch 1: 5.7835\n",
            "  Epoch 2: 5.0137\n",
            "  Epoch 3: 4.8451\n",
            "  Epoch 4: 4.7378\n",
            "  Epoch 5: 4.7060\n",
            "  Epoch 6: 4.7390\n",
            "  Epoch 7: 4.7018\n",
            "  Epoch 8: 4.7135\n",
            "  Epoch 9: 4.6814\n",
            "  Epoch 10: 4.7460\n",
            "  Epoch 11: 4.7517\n",
            "  Epoch 12: 4.7922\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for model_name, history in zip([\"RNN\", \"LSTM\", \"GRU\"], [history_ppl_rnn, history_ppl_lstm, history_ppl_gru]):\n",
        "    print(f\"Perplexity for {model_name}:\")\n",
        "    for epoch, val in enumerate(history, 1):\n",
        "        print(f\"  Epoch {epoch}: {val:.4f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhy5hZN38qfO"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,452</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m6,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │        \u001b[38;5;34m65,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m52\u001b[0m)         │        \u001b[38;5;34m10,452\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">165,818</span> (647.73 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m165,818\u001b[0m (647.73 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,908</span> (323.86 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m82,908\u001b[0m (323.86 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,910</span> (323.87 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m82,910\u001b[0m (323.87 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cargo los modelos guardados del entrenamiento para hacer inferencia\n",
        "model_rnn = keras.models.load_model('model_rnn.keras')\n",
        "model_lstm = keras.models.load_model('model_lstm.keras')\n",
        "model_gru = keras.models.load_model('model_gru.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "JoFqRC5pxzqS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I was far more willing to allow that this chimney of the sound of the so'"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='I was far more willing to allow that this chimney of'\n",
        "\n",
        "generate_seq(model_rnn, input_text, max_length=max_context_size, n_words=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The man a started the sound of the sound of the sound of the sound of the sound of the sound of the sound o\n"
          ]
        }
      ],
      "source": [
        "print(generate_seq(model_rnn, \"The man\", max_length=max_context_size, n_words=100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model_rnn,num_beams=10,num_words=20,input=\"habia una vez\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "P8HQoLhw-NYg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([32, 25, 26, 33, 25,  0, 45, 38, 25,  0, 46, 29, 50, 50, 29, 38, 44,\n",
              "       33, 39, 38,  0, 39, 30,  0, 44, 32, 29,  0, 29, 25, 42, 44, 32])"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "salidas[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "2S3_I3S1W1Hm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'habia una vezzention of the earth'"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Probamos tres estrategias de generación: Greedy, Beam Search determinístico y Beam Search estocástico. Greedy tiende a generar secuencias más repetitivas, ya que siempre elige la opción más probable. Beam Search determinístico permite mayor diversidad manteniendo las secuencias más probables, mientras que el estocástico introduce aleatoriedad controlada por la temperatura, generando resultados más variados. A temperaturas bajas (por ejemplo, 0.5) se privilegian opciones más seguras, mientras que temperaturas altas (1.0 o más) producen secuencias más impredecibles."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
